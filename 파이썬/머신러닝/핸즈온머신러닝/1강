머신러닝은 스팸필터가 대표적이다. 이후 음성 검색 및 추천으로 발전했다.

머신러닝은 어디서 시작하고 어디서 끝날까? 기계가 배운다는 것은 무엇일까?



1.1 머신러닝이란?

데이터에서부터 학습하도록 컴퓨터 프로그래밍하는 과학이다.

-명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다.

-어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정햇을 때 경험 E로 인해 성능이 향상됐다면 이는 컴퓨터 프로그램은 작업T와 성능 측정 P에 대해 경험 E로 학습한 것이다.



ex) 스팸필터

훈련세트:학습하는데 사용되는 샘플

훈련 사례: 각 훈련 데이터

작업T: 새로운 메일이 스팸인지 구분

경험E: 훈련 데이터

성능측정 P:정확도





1.2 왜 머신러닝을 사용하는가?

전통적인 스팸필터

1) 스팸에 어떤 단어가 있는지 본다. 

'신용카드', '무료', '굉장한' 등이 있다. 혹은 메일 주소를 필터링한다.

2) 알고리즘을 작성하여 이런 패턴은 스팸으로 간주한다.

3) 프로그램을 테스트하고 론칭할만큼 1과 2를 반복한다.



반면 머신러닝을 자동으로 학습한다.

만약 4U가 포함한 메일을 스팸을 분류했다면 For U로 했다면, 전통적에선 프로그래밍을 수정해야하지만, 머신러닝은 이것이 자주 나타난다는 것을 발견해 자동으로 수정한다.



데이터마이닝(data mining): 머신러닝 기술을 적용해 기존에 보이지 않는 패턴을 발견한다.



머신러닝이 뛰어난 분야

-기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제





1.3 애플리케이션 사례

상품추천

게임봇

스팸필터

종양진단 등



1.4 머신러닝 시스템의 종류



지도, 비지도, 준지도, 강화학습

온라인학습과 배치학습

사례 기반 학습과 모델 기반 학습



1.4.1 지도 학습과 비지도 학습

'학습하는 동안의 감독 형태나 정보량'에 따라 분류



지도학습

알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함



분류: 전형적인 지도 학습.

스팸필터가 좋은 예다.

회귀

중고차 가격 예측-예측 변수로 불리는 특성(주행거리, 연식 등)



로지스틱회귀

클래스에 속할 확률을 출력





비지도 학습

말 그대로 훈련 데이터에 레이블이 없다. 시스템에 아무런 도움없이 학습한다.

군집, 시각화, 차원축소, 연관규칙학습





준지도 학습

일부만 레이블이 있고 일부는 레이블이 없는 상태





강화학습

학습하는 시스템을 에이전트라 부르며, 환경을 관찰하고 행동해서 그 결과로 보상을 받거나 벌점을 받는다. 가장 큰 보상을 얻기 위한 정책을 최상의 전략으로 여긴다.





1.4.2 배치  학습과 온라인 학습

데이터의 스트림으로부터 점진적으로 학습할 수 잇는지 여부입니다.



배치학습

시스템이 점진적으로 학습할 수 없고, 가용한 데이터를 모두 사용해 훈련시켜야 한다.

오프라인 학습이라고도 한다.



온라인학습

데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위를 주입하여 시스템을 훈련시킨다.

온라인 학습에서 문제점은 나쁜 데이터가 계속 들어오면 성능저하가 일어난다.



1.4.3 사례 기반 학습과 모델 기반 학습



사례기반 학습

시스템의 훈련 샘플을 기억해서 학습한다.



ex) 메일 분류

두 메일 사이에 공통으로 포함된 단어를 세서 유사도를 측정후 분류한다.



모델기반학습

샘플들의 모델을 만들어 예측에 사용하는 것.



1.5 머신러닝의 주요 도전 과제

'나쁜 알고리즘'과 '나쁜 데이터'



1.5.1 충분하지 않은 양의 훈련 데이터



1.5.2 대표성 없는 훈련 데이터

-표본을 잘 못뽑았다.



1.5.3 낮은 품질의 데이터

에러, 이상치, 잡음이 많다



1.5.4 관련 없는 특성



1.5.5 훈련 데이터의 과대적합

훈련데이터에는 잘맞지만 일반성이 떨어지는 것



해결방법

-파라미터 수가 적은 모델을 선택하거나 모델에 제약을 가하여 단순화시킨다

-훈련 데이터를 더 모은다

-훈련 데이터의 잡음을 제거한다.(오류 데이터 수정 및 이상치 제거)



1.5.6 훈련 데이터 과소적합

모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못한다.



해결방법

-모델 파라미터가 더 많은 강력한 모델을 선택

-학습 알고리즘에 더 좋은 특성을 제공

-모델의 제약을 줄인다.



1.6 테스트와 검증

1.6.1 하이퍼파라미터 튜닝과 모델 선택



공짜 점심 없음 이론

no free lunch(NFL)이론: 어떤 데이터셋에는 선형 모델이 가장 잘 맞지만, 다른 모델엔 신경망이 잘 맞는다. 어떤 모델이 가장 잘 맞는지 평가하는 방법은 모든 모델을 평가하는 것 뿐이다. 이것이 실전에서 불가능하기에 몇몇 그럴싸한 것만 한다.
