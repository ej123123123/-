2.1 응용선형대수



수학= 목적함수+최적화 -> 선형대수

알고리즘= 수학+제어 ->확률과 통계

사람= 알고리즘+데이터 ->최적화





데이터의 표현 방식



스칼라 0차원 텐서

벡터 1차원 텐서

행렬 2차원 텐서

텐서 3차원 이상



전치행렬(Transpose Matrix)

A=(3 4 1)

    0 5 2





A^T=(3 0)

        4 5

        1 2



행렬의 곱셈



A의 행과 B의 열의 개수가 맞아야한다.



A(B+C)=AB+BC

A(BC)=(AB)C

AB!=BA



행렬분해

고유벡터 v(Eigen vector)

0아 아닌 벡터

모든 고유벡터는 서로 직교



고윳값 Eigen Value

A=(2 1) -> 행렬분해 (2 1)( 1) = 3(1)

    (1 2)                  (1 2)(1) =   (1)



고윳값=3, 고유백터 (1)

                          (1)



고윳값 분해(Eigen Value Decomposition)

행렬 A가 정사각형인 이유

A=QAQ^-1



특잇값 분해(Singular Value Decomposition)



놈(Norm)

데이터들의 유사도를측정할 수 있는 방법






퍼셉트론(Perceptron)

기계학습에 나타나는 가중치와 출력 등을 행렬로 간단하게 표현할 수 있다.



학습의 정의



학습 과정

샘플이 주어졌을 떄 샘플을 제대로 분류하는 W를 구하는 문제

O= T(W,X)

O 아는 값

W 구해야 할 값

X 아는값



분류과정

가중치 행렬 W를 알고 있을 때 새로운 특정 벡터 x가 주어졌을 때 출력값 o를계산하는 것

O= 모르는 값

W= 아는 값

X 아는 값





2-2 확률과 통계



확률분포(Probability Distribution)

결합확률분포: 다수의 변수에 관한 확률분포

조건부확률: (X=x일때 Y=y일 확률)

P(Y=y|X=x)



베이즈정리

(x와 y가 같이 일어날 결합확률= y와 x가 같이 일어날 결합확률)

P(y|x) = (p(x|y)*P(y))/P(x)








최대우도법(Maximum Likelihood)




우도가 최대가 되는 해를 찾는 것





정보이론(Information Theory)

메시지의 정보량을 확률로 측정함



h(ei)=-log2P(ei)




확률이 많을수록 정보가 많다.





엔트로피

확률분포의 무질서도 또는 불확실성 측정






2.3 최적화



전역 최적해(Global optimal Solution) - 전체에서 최소인 점

지역 최적해(Local Optimal Solution) - 특정 구간에서 최소인 점



전역 최적해에 비슷한 지역 최적해를 구하는 것이 좋다.



최적화 알고리즘

 낱낱검색(Exhausitive Search): 해 공간을 샅샅이 뒤진다. 전부 검색





미분(Differentiation)

도함수가 +면 -방향으로, 도함수가 -면 +방향으로 가야 최저점을 만난다.



편미분법

연쇄법칙(Chain Rule)

함성함수의 미분



경사하강법

학습률과 그레디언트 값을 계산하여 매개변수의 값을 갱신하는 방법






